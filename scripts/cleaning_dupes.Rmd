---
title: "Getting lists of duplicates"
date: "Updated: `r Sys.Date()`"
output:
  html_document:
    toc: false
---


```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.retina = 4)
```


```{r message=FALSE, warning=FALSE}
# Libraries
pacman::p_load(tidyverse, countrycode, sf, state, htmltools, htmlwidgets, urltools, janitor, DT, RColorBrewer, plotly)

# Data
df <- read_csv(here::here("data/beacon-latest/beacon-2021-02-02.csv"))
#shapefile <- read_sf(here::here("data/TM_WORLD_BORDERS_SIMPL-0.3.shp"))
tld <- read_csv(here::here("data/tld-country.csv"))
tld_from_ip <- read_csv(here::here("data/tld_from_ip.csv"))

canada.states <- 
  c("Alberta", "British Columbia", "Labrador", "Manitoba", "New Brunswick", "Newfoundland", "Nova Scotia", "Nunavut", "North West Terr.", "Ontario", "Prince Edward Is.", "QuÃ©bec (Province)", "Saskatchewan", "Yukon")
```


```{r}
# correcting some oai urls
df <- 
  df %>% 
  mutate(oai_url = if_else(str_detect(oai_url, "^//"), str_c("http:", oai_url), oai_url))
```


```{r}
# getting domain and tld
df <- 
  bind_cols(
    df,
    df %>% pull(oai_url) %>% domain() %>% tld_extract()
  ) %>% 
  left_join(tld_from_ip, by = "domain") %>%
  mutate(
    tld = if_else(!is.na(tld_from_ip), tld_from_ip, tld)
  ) %>%
  left_join(tld, by = "tld")
```


```{r}
# Cleaning countries + Mapping countries to continents
df <-
  df %>% 
  mutate(
    country = if_else(is.na(country), country_clean, country),
    ojs_v2 = str_detect(version, "^ojs2/2"),
    ojs_v3 = str_detect(version, "^ojs2/3"),
    version_clean = case_when(
      ojs_v2 ~ "Version 2",
      ojs_v3 ~ "Version 3",
      TRUE ~ "Other"
    )
  ) %>% 
  mutate(
    country = if_else(country == "Washington (State)", "United States", country),
    country = if_else(str_detect(country, "United States|New York|District of Columbia"), "United States", country),
    country = if_else(country %in% state.name, "United States", country),
    country = if_else(country %in% canada.states, "Canada", country),
    country = if_else(str_detect(country, "China"), "China", country),
    country = if_else(str_detect(country, "Armenia"), "Armenia", country),
    country = if_else(str_detect(country, "Georgia"), "Georgia", country),
    country = if_else(str_detect(country, "Australia|New South Wales|Queensland|Victoria"), "Australia", country),
    country = if_else(str_detect(country, "England"), "United Kingdom", country),
    country = if_else(str_detect(country, "Russia|Soviet Union"), "Russia", country),
    country = if_else(str_detect(country, "Palestine"), "Palestine", country),
    country = if_else(country == "Korea (South)", "South Korea", country)
  )

continents <-
  df %>%
  pull(country) %>% 
  countrycode(origin = "country.name", destination = "continent")

df <- df %>% bind_cols(continents)

# rename last column to `continent`
names(df)[length(names(df))] <- "continent"

rm(tld, tld_from_ip)

df %>% filter(total_record_count > 0) %>% summarise_all(~ mean(is.na(.)))
```


Noting dupes:

```{r}
df %>% 
  drop_na(issn) %>% get_dupes(issn) %>% arrange(issn, desc(dupe_count)) %>% 
  write_csv(here::here("beacon_duplicates", "duplicates_by_issn.csv"))

df %>% 
  drop_na(issn) %>% get_dupes(issn, repository_name) %>% arrange(issn, repository_name, desc(dupe_count)) %>% 
  write_csv(here::here("beacon_duplicates", "duplicates_by_issn_reponame.csv"))

df %>% 
  drop_na(issn) %>% get_dupes(issn, domain) %>% arrange(issn, domain, desc(dupe_count)) %>% 
  write_csv(here::here("beacon_duplicates", "duplicates_by_issn_domain.csv"))
```


```{r}
df %>% 
  drop_na(issn) %>% get_dupes(issn, repository_name, set_spec) %>% arrange(issn, repository_name, set_spec, desc(dupe_count)) %>% 
  write_csv(here::here("beacon_duplicates", "duplicates_by_issn_reponame_setspec.csv"))

df %>% 
  filter(is.na(issn) & total_record_count > 0) %>% 
  drop_na(repository_name, admin_email) %>% 
  get_dupes(repository_name, admin_email) %>% arrange(repository_name, admin_email, desc(dupe_count))

df %>% 
  filter(is.na(issn) & total_record_count > 0) %>% 
  drop_na(repository_name, admin_email, set_spec) %>% 
  get_dupes(repository_name, admin_email, set_spec) %>% arrange(repository_name, admin_email, set_spec, desc(dupe_count))
```



```{r}
# Stats for John #

df_world <-
  df %>%
  filter(record_count_2019 >= 5) %>% 
  drop_na(country) %>%   
  group_by(country, continent) %>% 
  summarize(
    ojs_v2 = sum(ojs_v2, na.rm = T),
    ojs_v3 = sum(ojs_v3, na.rm = T)
  ) %>% 
  ungroup() %>% 
  transmute(
    country,
    continent,
    ojs_v2,
    ojs_v3,
    total = ojs_v2 + ojs_v3
  ) %>% 
  mutate(
    total = replace_na(total, 0),
    ojs_v2 = replace_na(ojs_v2, 0),
    ojs_v3 = replace_na(ojs_v3, 0)
  )


df_world %>% 
  summarise(
    total = sum(total, na.rm = TRUE),
    ojs_v2 = sum(ojs_v2, na.rm = TRUE),
    ojs_v3 = sum(ojs_v3, na.rm = TRUE)
  )

df_world %>% arrange(-total) %>% select(-continent)
```

```{r}
df %>%
  filter(record_count_2019 >= 5 & country == "Indonesia" & ojs_v2) %>% 
  count(domain, name = "ojs_v2_journals") %>% 
  arrange(-ojs_v2_journals) %>% 
  datatable()
```

