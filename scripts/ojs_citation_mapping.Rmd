---
title: "OJS Citation Mapping Analysis"
date: "Updated: `r format(Sys.Date(), format='%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 6
    number_sections: yes
---

---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.retina = 4)
```


```{r message=FALSE, warning=FALSE}
# Libraries
pacman::p_load(tidyverse, countrycode, sf, state, htmltools, htmlwidgets, urltools, janitor, DT, RColorBrewer, plotly, readxl, ggforce)
tld <- read_csv(here::here("data/tld-country.csv"))
tld_from_ip <- read_csv(here::here("data/tld_from_ip.csv"))

# world map shapefile
shapefile <-
  read_sf(here::here("data/TM_WORLD_BORDERS_SIMPL-0.3.shp")) %>%
  clean_names() %>%
  filter(name %in% c("Western Sahara", "Morocco")) %>% # handling boundary issues for morocco and western sahara
  mutate(name = if_else(name == "Western Sahara", "Morocco", name)) %>%
  arrange(name) %>%
  group_by(name) %>%
  summarize(
    geometry = st_union(geometry),
    lat = first(lat),
    lon = first(lon),
    region = first(region),
    subregion = first(subregion)
  ) %>%
  st_cast("MULTIPOLYGON") %>% 
  bind_rows(
    read_sf(here::here("data/TM_WORLD_BORDERS_SIMPL-0.3.shp")) %>%
      clean_names() %>%
      filter(!(name %in% c("Western Sahara", "Morocco")))
  )
```


# Global Statistics

```{r}
# Data (Aug 5, 2021)
df <- read_csv(here::here("data/jonas/report-2021.csv"))

canada.states <- 
  c("Alberta", "British Columbia", "Labrador", "Manitoba", "New Brunswick", "Newfoundland", "Nova Scotia", "Nunavut", "North West Terr.", "Ontario", "Prince Edward Is.", "QuÃ©bec (Province)", "Saskatchewan", "Yukon")

# correcting some oai urls
df <- 
  df %>% 
  mutate(oai_url = if_else(str_detect(oai_url, "^//"), str_c("http:", oai_url), oai_url))


# getting domain and tld
df <-  
  bind_cols(
    df,
    df %>% pull(oai_url) %>% domain() %>% tld_extract()
  ) %>% 
  mutate(country_consolidated = str_to_lower(country_consolidated) %>% str_trim()) %>% 
  left_join(tld, by = c("country_consolidated" = "tld"))

# Cleaning countries + Mapping countries to continents
df <-
  df %>% 
  mutate(
    country = country_clean,
    ojs_v2 = str_detect(version, "^2"),
    ojs_v3 = str_detect(version, "^3"),
    version_clean = case_when(
      ojs_v2 ~ "Version 2",
      ojs_v3 ~ "Version 3",
      TRUE ~ "Other"
    )
  ) %>% 
  mutate(
    country = if_else(country == "Washington (State)", "United States", country),
    country = if_else(str_detect(country, "United States|New York|District of Columbia"), "United States", country),
    country = if_else(country %in% state.name, "United States", country),
    country = if_else(country %in% canada.states, "Canada", country),
    country = if_else(str_detect(country, "China"), "China", country),
    country = if_else(str_detect(country, "Armenia"), "Armenia", country),
    country = if_else(str_detect(country, "Georgia"), "Georgia", country),
    country = if_else(str_detect(country, "Australia|New South Wales|Queensland|Victoria"), "Australia", country),
    country = if_else(str_detect(country, "England|British"), "United Kingdom", country),
    country = if_else(str_detect(country, "Russia|Soviet Union"), "Russia", country),
    country = if_else(str_detect(country, "Palestine"), "Palestine", country),
    country = if_else(country == "Korea (South)", "South Korea", country)
  ) %>% 
  select(-country_clean)

continents <-
  df %>%
  pull(country) %>% 
  countrycode(origin = "country.name", destination = "continent")

df <- df %>% bind_cols(continents)

# rename last column to `continent`
names(df)[length(names(df))] <- "continent"
```


```{r}
df <-
  df %>%
  separate(oai_url, c("url1", "url2"), "\n") %>% 
  remove_empty() %>%
  rename(oai_url = url1) %>%
  select(-url2) %>% 
  filter(!str_detect(oai_url, "\\?page=")) %>%
  mutate(
    url = str_replace(oai_url, "index/oai", set_spec),
    url = str_replace(url, "^https://", ""),
    url = str_replace(url, "^http://", ""),
    url = str_replace(url, "^www108.", ""),
    url = str_replace(url, "^www5.", ""),
    url = str_replace(url, "^www3.", ""),
    url = str_replace(url, "^www2.", ""),
    url = str_replace(url, "^www.", ""),
  ) %>%
  bind_rows(
    df %>%
      separate(oai_url, c("url1", "url2"), "\n") %>%
      remove_empty() %>%
      rename(oai_url = url1) %>%
      select(-url2) %>%
      filter(str_detect(oai_url, "\\?page=")) %>%
      mutate(
        url = str_replace(oai_url, "oai$", set_spec),
        url = str_replace(url, "^https://", ""),
        url = str_replace(url, "^http://", ""),
        url = str_replace(url, "^www108.", ""),
        url = str_replace(url, "^www5.", ""),
        url = str_replace(url, "^www3.", ""),
        url = str_replace(url, "^www2.", ""),
        url = str_replace(url, "^www.", ""),
      )
  ) %>% 
  rename(journal_url = url)

# active ojs journals
df_2021 <-
  df %>% 
  filter(total_record_count > 0, application == "ojs") %>%
  distinct(oai_url, repository_name, set_spec, .keep_all = T) %>%
  mutate(active = (record_count_2021 >= 5)) %>% 
  filter(active)
```


```{r, eval=F}
# extracting ISSNs for Charlie

df %>%
  filter(total_record_count > 0, application == "ojs") %>%
  filter(total_record_count >= record_count_2021) %>%
  distinct(oai_url, repository_name, set_spec, .keep_all = T) %>% 
  separate(issn, c("issn1", "issn2"), "\n") %>%
  select(
    journal_name = context_name,
    issn1,
    issn2,
    journal_url,
    record_count_2021,
    total_record_count
  ) %>% glimpse() 
  # write_csv(here::here("ojs_2021_issns.csv"))
```

