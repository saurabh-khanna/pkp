---
title: "OAI Scrape"
author: "Saurabh Khanna"
date: "`r Sys.Date()`"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.retina = 4)
```


```{r message=FALSE, warning=FALSE}
# Libraries
pacman::p_load(tidyverse, countrycode, sf, state, htmltools, htmlwidgets, urltools, janitor, DT, RColorBrewer, plotly)

# Data
df <- read_csv(here::here("data/beacon-latest/beacon.csv"))
tld <- read_csv(here::here("data/tld-country.csv"))
tld_from_ip <- read_csv(here::here("data/tld_from_ip.csv"))

canada.states <- 
  c("Alberta", "British Columbia", "Labrador", "Manitoba", "New Brunswick", "Newfoundland", "Nova Scotia", "Nunavut", "North West Terr.", "Ontario", "Prince Edward Is.", "QuÃ©bec (Province)", "Saskatchewan", "Yukon")
```


```{r}
# correcting some oai urls
df <- 
  df %>% 
  mutate(oai_url = if_else(str_detect(oai_url, "^//"), str_c("http:", oai_url), oai_url))
```


```{r}
# getting domain and tld
df <- 
  bind_cols(
    df,
    df %>% pull(oai_url) %>% domain() %>% tld_extract()
  ) %>% 
  left_join(tld_from_ip, by = "domain") %>%
  mutate(
    tld = if_else(!is.na(tld_from_ip), tld_from_ip, tld)
  ) %>%
  left_join(tld, by = "tld")
```


```{r}
# Cleaning countries + Mapping countries to continents
df <-
  df %>% 
  mutate(
    country = if_else(is.na(country), country_clean, country),
    ojs_v2 = str_detect(version, "^ojs2/2"),
    ojs_v3 = str_detect(version, "^ojs2/3"),
    version_clean = case_when(
      ojs_v2 ~ "Version 2",
      ojs_v3 ~ "Version 3",
      TRUE ~ "Other"
    )
  ) %>% 
  mutate(
    country = if_else(country == "Washington (State)", "United States", country),
    country = if_else(str_detect(country, "United States|New York|District of Columbia"), "United States", country),
    country = if_else(country %in% state.name, "United States", country),
    country = if_else(country %in% canada.states, "Canada", country),
    country = if_else(str_detect(country, "China"), "China", country),
    country = if_else(str_detect(country, "Armenia"), "Armenia", country),
    country = if_else(str_detect(country, "Georgia"), "Georgia", country),
    country = if_else(str_detect(country, "Australia|New South Wales|Queensland|Victoria"), "Australia", country),
    country = if_else(str_detect(country, "England|British"), "United Kingdom", country),
    country = if_else(str_detect(country, "Russia|Soviet Union"), "Russia", country),
    country = if_else(str_detect(country, "Palestine"), "Palestine", country),
    country = if_else(country == "Korea (South)", "South Korea", country)
  ) %>% 
  select(-country_clean)

continents <-
  df %>%
  pull(country) %>% 
  countrycode(origin = "country.name", destination = "continent")

df <- df %>% bind_cols(continents)

# rename last column to `continent`
names(df)[length(names(df))] <- "continent"

rm(tld, tld_from_ip)
```


```{r}
# df %>% 
#   filter(country == "Morocco") %>% 
#   write_csv(here::here("data/beacon-latest/beacon-morocco.csv"))
```















```{r}
# test_url <-
#   df %>% 
#   group_by(oai_url) %>% 
#   summarize(total = sum(total_record_count, na.rm = TRUE)) %>%
#   filter(total == 0) %>%
#   sample_n(1) %>% 
#   pull(oai_url)
# 
# list_identifiers(test_url)
```


```{r}
x <- list_identifiers("https://ojs.stanford.edu/ojs/index.php/index/oai")
x
```

```{r}
y <- list_records("https://ojs.stanford.edu/ojs/index.php/index/oai")
#y %>% write_csv("ojs_records_stanford.csv")
```

```{r}
y %>% select(contains("source"), everything())

# issye year not same as pub year problem
y %>% 
  transmute(
    journal = word(setSpec, 1, sep = "\\:") %>% str_to_upper() %>% str_trim(),
    pub_year = str_sub(date, 1, 4) %>% as.integer(),
    issue_year = str_extract(source, "(19|20)\\d{2}") %>% as.integer(),
    url = identifier.1
  ) %>% 
  arrange(journal) %>% 
  filter(pub_year != issue_year)
```

```{r}
y %>% 
  transmute(
    year = str_sub(date, 1, 4),
    journal = word(setSpec, 1, sep = "\\:") %>% str_to_upper() %>% str_trim()
  ) %>% 
  count(journal, year) %>% 
  drop_na(year) %>% 
  pivot_wider(names_from = year, values_from = n) %>% 
  mutate_all(~ replace_na(., 0)) %>% 
  mutate(
    total =
      pmap_dbl(
        select(., starts_with("2")),
        ~ sum(c(...), na.rm = TRUE)
      )
  ) %>% 
  select(journal, total, sort(tidyselect::peek_vars(), decreasing = T))
```


```{r}
y %>% 
  transmute(
    year = str_sub(date, 1, 4),
    journal = word(setSpec, 1, sep = "\\:") %>% str_to_upper() %>% str_trim()
  ) %>% 
  count(journal, year) %>% 
  drop_na(year) %>% 
  pivot_wider(names_from = year, values_from = n) %>% 
  mutate_all(~ replace_na(., 0)) %>%
  pivot_longer(-journal, names_to = "year", values_to = "records") %>%
  arrange(desc(journal)) %>% 
  ggplot(aes(year, records, group = journal, color = journal)) +
  geom_point() +
  geom_line(size = 0.8) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(
    x = "Publication Year",
    y = "Records",
    color = "Journal"
  )
```



```{r}
y %>% 
  mutate(
    publication_date = date,
    pub_year_src1 = str_sub(date, 1, 4),
    journal = word(setSpec, 1, sep = "\\:") %>% str_to_upper() %>% str_trim(),
    pub_year_src2 = str_sub(date, 1, 4),
    date = lubridate::ymd(date)
  ) %>% 
  filter(str_detect(journal, "INTERSECT")) %>% 
  arrange(date) %>% 
  select(journal, pub_year_src1, pub_year_src2, identifier.1, relation)
```


