---
title: "Predatory Publishing Results"
date: "Updated: `r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 4
---


```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.retina = 4)
```


```{r message=FALSE, warning=FALSE}
# Libraries
pacman::p_load(tidyverse, countrycode, sf, state, htmltools, htmlwidgets, urltools, janitor, DT, RColorBrewer, plotly, readxl, writexl, cowplot)
tld <- read_csv(here::here("data/tld-country.csv"))
tld_from_ip <- read_csv(here::here("data/tld_from_ip.csv"))
```



```{r}
# Data (May 17, 2021)
df <- read_csv(here::here("data/jonas/beacon-public.csv"))

canada.states <- 
  c("Alberta", "British Columbia", "Labrador", "Manitoba", "New Brunswick", "Newfoundland", "Nova Scotia", "Nunavut", "North West Terr.", "Ontario", "Prince Edward Is.", "QuÃ©bec (Province)", "Saskatchewan", "Yukon")

# correcting some oai urls
df <- 
  df %>% 
  mutate(oai_url = if_else(str_detect(oai_url, "^//"), str_c("http:", oai_url), oai_url))


# getting domain and tld
df <-  
  bind_cols(
    df,
    df %>% pull(oai_url) %>% domain() %>% tld_extract()
  ) %>% 
  mutate(country_consolidated = str_to_lower(country_consolidated) %>% str_trim()) %>% 
  left_join(tld, by = c("country_consolidated" = "tld"))

# Cleaning countries + Mapping countries to continents
df <-
  df %>% 
  mutate(
    country = country_clean,
    ojs_v2 = str_detect(version, "^2"),
    ojs_v3 = str_detect(version, "^3"),
    version_clean = case_when(
      ojs_v2 ~ "Version 2",
      ojs_v3 ~ "Version 3",
      TRUE ~ "Other"
    )
  ) %>% 
  mutate(
    country = if_else(country == "Washington (State)", "United States", country),
    country = if_else(str_detect(country, "United States|New York|District of Columbia"), "United States", country),
    country = if_else(country %in% state.name, "United States", country),
    country = if_else(country %in% canada.states, "Canada", country),
    country = if_else(str_detect(country, "China"), "China", country),
    country = if_else(str_detect(country, "Armenia"), "Armenia", country),
    country = if_else(str_detect(country, "Georgia"), "Georgia", country),
    country = if_else(str_detect(country, "Australia|New South Wales|Queensland|Victoria"), "Australia", country),
    country = if_else(str_detect(country, "England|British"), "United Kingdom", country),
    country = if_else(str_detect(country, "Russia|Soviet Union"), "Russia", country),
    country = if_else(str_detect(country, "Palestine"), "Palestine", country),
    country = if_else(country == "Korea (South)", "South Korea", country)
  ) %>% 
  select(-country_clean)

continents <-
  df %>%
  pull(country) %>% 
  countrycode(origin = "country.name", destination = "continent")

df <- df %>% bind_cols(continents)

# rename last column to `continent`
names(df)[length(names(df))] <- "continent"

df <-
  df %>% 
  filter(total_record_count > 0) %>% 
  filter(application == "ojs") %>% 
  mutate(
    # record_count_from_2019 = record_count_2019 + record_count_2020 + record_count_2021,
    # active = (record_count_from_2019 >= 10),
    # active2019 = (record_count_2019 >= 5),
    active = (record_count_2020 >= 5),
    # active2021 = (record_count_2021 >= 5)
  ) %>%
  distinct(oai_url, repository_name, set_spec, .keep_all = T)

# df %>% 
#   filter(record_count_2020 >= 10) %>% 
#   count(continent)
```


```{r, eval=FALSE}
df %>% summarize_all(~ sum(is.na(.)))
df %>% glimpse()

df %>% count(active) # 25671
df %>% drop_na(country) %>% count(active) # 25577

df %>% drop_na(country) %>% filter(active) %>% distinct(domain)
```

```{r, eval=FALSE}
# JUST FOR MIRO (IGNORE OTHERWISE)
df <-
  df %>%
  mutate(
    issn = str_extract(issn, "[^\n]+"),
    oai_url = str_extract(oai_url, "[^\n]+"),
    journal_url = str_extract(oai_url, ".+?(?=oai)"),
    journal_name = context_name,
    issn = if_else(issn == "2153-2249", "2153-2257", issn)
  )
  

readxl::read_excel(here::here("data/OJS and PR overlap.xlsx")) %>%
  inner_join(df, by = c("issn", "journal_url", "journal_name")) %>% 
  select(publisher = repository_name, journal_name, issn, journal_url, admin_email, country, version, total_record_count) %>% 
  arrange(publisher, journal_name) %>% distinct(admin_email)
  #writexl::write_xlsx(here::here("ojs_cabells_overlap_for_miroslav_01.14.2022.xlsx"))

```


```{r}
# predatory matching

#### optional part
df <-
  df %>%
  mutate(
    issn = str_extract(issn, "[^\n]+"),
    oai_url = str_extract(oai_url, "[^\n]+"),
    journal_url = str_extract(oai_url, ".+?(?=oai)"),
    journal_name = context_name
  )



df_cabells <- 
  readxl::read_excel(here::here("data/ojs_journals_09.28.2021.xlsx")) %>% 
  left_join(df, by = c("issn", "journal_url", "journal_name"))
####


pred_list <- 
  read_csv("/Users/saurabh/Everything/GitHub/beall-live/data/df_weekly_publishers.csv") %>%
  bind_rows(read_csv("/Users/saurabh/Everything/GitHub/beall-live/data/df_weekly_standalone.csv")) %>% 
  clean_names() %>% 
  remove_empty()

pred_list <-
  bind_cols(
    pred_list,
    pred_list %>% pull(url) %>% domain() %>% tld_extract()
  ) %>% 
  relocate(domain) %>% 
  mutate(
    domain = str_replace(domain, "^www.", ""),
    alive = (status == 200),
    alive = if_else(is.na(alive), F, alive)
  ) %>% 
  distinct(domain, .keep_all = T)

df_pred <- 
  df_cabells %>%
  mutate(
    domain = str_replace(domain, "^www.", "")
  ) %>%
  inner_join(pred_list, by = "domain") %>%
  relocate(domain)

df_pred %>% count(country) %>% arrange(-n)

df_pred %>% distinct(domain)

readxl::read_excel(here::here("data/OJS and PR overlap.xlsx")) %>% 
  inner_join(df_pred, by = c("issn", "journal_url", "journal_name")) %>% 
  count(country) %>% 
  arrange(-n)

# 127 out of 2741 publisher domains (4.6% domains are in the beacon)
# 684 journals (372 active, 312 inactive) [1.4% active and 2.1% inactive OJS journals]. 118 of these are in DOAJ.
# US and India

366/25672

237-82

(1966)/2925

pred_list %>% tabyl(status)

read_csv("/Users/saurabh/Everything/GitHub/beall-live/data/df_weekly_publishers.csv") %>% tabyl(status)
read_csv("/Users/saurabh/Everything/GitHub/beall-live/data/df_weekly_standalone.csv") %>% tabyl(status)
```


```{r, fig.retina=4}
# figure for john's book chapter
df_beall_only <-
  readxl::read_excel(here::here("data/OJS and PR overlap.xlsx")) %>% 
  anti_join(df_pred, ., by = c("issn", "journal_url", "journal_name")) %>%
  tabyl(country) %>%
  as_tibble() %>% 
  arrange(-n) %>% 
  head(10) %>% 
  transmute(country = fct_inorder(country) %>% fct_rev(), n, percent, id = "Bealls List")

df_bc_both <-
  readxl::read_excel(here::here("data/OJS and PR overlap.xlsx")) %>% 
  inner_join(df_pred, by = c("issn", "journal_url", "journal_name")) %>% 
  tabyl(country) %>%
  as_tibble() %>% 
  arrange(-n) %>% 
  head(10) %>% 
  transmute(country = fct_inorder(country) %>% fct_rev(), n, percent, id = "Both")

df_cabell_only <-
  readxl::read_excel(here::here("data/OJS and PR overlap.xlsx")) %>% 
  anti_join(df_pred, by = c("issn", "journal_url", "journal_name")) %>% 
  left_join(df, by = c("issn", "journal_url", "journal_name")) %>% 
  tabyl(country) %>%
  as_tibble() %>% 
  arrange(-n) %>% 
  head(10) %>% 
  transmute(country = fct_inorder(country) %>% fct_rev(), n, percent, id = "Cabells List")


# bind_rows(df_beall_only, df_bc_both, df_cabell_only) %>% 
#   mutate(
#     country = fct_inorder(country) %>% fct_rev()
#   ) %>% 
#   ggplot(aes(country, percent)) +
#   geom_col() +
#   facet_wrap(vars(id), ncol=1) +
#   coord_flip() +
#   hrbrthemes::theme_ipsum()

p1 <-
  df_beall_only %>% 
  ggplot(aes(country, percent)) +
  geom_col() +
  geom_text(
    aes(label = n),
    nudge_y = 0.005,
    direction = "x",
    show.legend = F
  ) +
  coord_flip() +
  theme(axis.text.x = element_text(size = 8)) +
  hrbrthemes::theme_ipsum() +
  scale_y_continuous(
    #breaks = scales::breaks_width(0.03),
    labels = scales::percent_format(accuracy = 1)
  ) +
  labs(x = "", y = "")

p2 <-
  df_bc_both %>% 
  ggplot(aes(country, percent)) +
  geom_col() +
  geom_text(
    aes(label = n),
    nudge_y = 0.01,
    direction = "x",
    show.legend = F
  ) +
  coord_flip() +
  theme(axis.text.x = element_text(size = 8)) +
  hrbrthemes::theme_ipsum() +
  scale_y_continuous(
    #breaks = scales::breaks_width(0.03),
    labels = scales::percent_format(accuracy = 1)
  ) +
  labs(x = "", y = "")


p3 <-
  df_cabell_only %>% 
  ggplot(aes(country, percent)) +
  geom_col() +
  geom_text(
    aes(label = n),
    nudge_y = 0.01,
    direction = "x",
    show.legend = F
  ) +
  coord_flip() +
  theme(axis.text.x = element_text(size = 8)) +
  hrbrthemes::theme_ipsum() +
  scale_y_continuous(
    #breaks = scales::breaks_width(0.03),
    labels = scales::percent_format(accuracy = 1)
  ) +
  labs(x = "", y = "")

plot_grid(p1, p2, p3, labels = c("Beall's List (n=284)", 'Both lists (n=82)', 'Predatory Reports (n=155)'), label_size = 12, ncol=1)

ggsave(here::here("fig_phase2.png"))
```



```{r}
bind_cols(df_beall_only, df_bc_both, df_cabell_only) %>% 
  mutate_at(vars(starts_with("percent")), ~ round(. * 100, 2)) %>%
  clean_names() %>% 
  mutate(
    count_1 = str_c(n_2, " (", percent_3, "%)"),
    count_2 = str_c(n_6, " (", percent_7, "%)"),
    count_3 = str_c(n_10, " (", percent_11, "%)")
  ) %>% 
  select(country_1, count_1, country_5, count_2, country_9, count_3) #%>% 
#  write_xlsx(here::here("ojs_beall_cabell_overlap_top10country.xlsx"))
```




&nbsp;

```{r}
# merging in doaj data
df_doaj <- 
  read_excel(here::here("data/kevin/kevin_doaj.xlsx")) %>% clean_names() %>% 
  remove_empty()

df_doaj <-
  bind_cols(
    df_doaj,
    df_doaj %>% pull(journal_url) %>% domain() %>% tld_extract()
  ) %>%
  mutate(
    platform = platform_host_or_aggregator %>% str_trim() %>% str_to_upper(),
    journal_title = journal_title %>% str_trim() %>% str_to_upper(),
    publisher = publisher %>% str_trim() %>% str_to_upper(),
    country = country_of_publisher %>% str_trim(),
    issn = journal_eissn_online_version %>% str_trim(),
    ojs = str_detect(platform, "OJS|NEPJOL|AJOL|SEER|OPEN JOURNAL SYSTEM"),
    domain = str_replace(domain, "^www.", ""),
    doaj = TRUE
  ) %>% 
  filter(ojs)

df_pred <-
  df_pred %>%
  left_join(df_doaj %>% distinct(domain, doaj), by = "domain") %>% 
  mutate(doaj = if_else(is.na(doaj), FALSE, doaj))


df_doaj %>% 
  anti_join(df, by = "issn")
```


## OJS journals matching Beall's List

```{r}
table1 <-
  df_pred %>%
  select(country, context_name, url, active) %>% 
  arrange(country, context_name) 

table1 %>%
  mutate(url = str_c('<a href="', url, '" target="_blank">', url, '</a>')) %>% 
  datatable(escape = F)
```

&nbsp;

Intersections:

```{r}
expressionInput <- c(ojs_active = 30332, ojs_inactive = 12248, beall = 2741, `ojs_active&ojs_inactive` = 0, `ojs_active&beall` = 406, 
                     `ojs_inactive&beall` = 298, `ojs_active&ojs_inactive&beall` = 0)

upset(fromExpression(expressionInput), order.by = "freq")
```


&nbsp;

## Additional analyses

### Domains matching Beall's List with OJS journal count

```{r}
table2 <-
  df_pred %>% 
  count(domain, name = "journals") %>% 
  arrange(-journals) 

table2 %>% 
  mutate(domain = str_c('<a href=http://"', domain, '" target="_blank">', domain, '</a>')) %>% 
  datatable(escape = F)
```


&nbsp;

### OJS journals matching Beall's list by country

```{r}
table3 <- df_pred %>% count(country, name = "journals") %>% arrange(-journals)

datatable(table3)
```



```{r}
# ### Active/Alive/DOAJ Breakdown for 704 OJS journals matching Beall's list
# 
# table4 <- df_pred %>% count(active, alive, doaj, name = "journals")
# 
# table4 %>% knitr::kable()
```


&nbsp;

### Average articles per year - Predatory vs Overall

```{r}
table5 <-
  df %>% 
  select(active, record_count_2018, record_count_2019, record_count_2020) %>% 
  group_by(active) %>% 
  summarize_all(~ mean(., na.rm = T)) %>% 
  mutate(type = "overall") %>% 
  bind_rows(
    df_pred %>% 
      select(active, record_count_2018, record_count_2019, record_count_2020) %>%
      group_by(active) %>% 
      summarize_all(~ mean(., na.rm = T)) %>% 
      mutate(type = "predatory")
  ) %>% 
  relocate(type)

table5 %>% knitr::kable()
```


```{r, eval=F}
# writing all tables to excel 
sheets <- list(
  "OJS journals matching Bealls List" = table1, 
  "Domains matching Bealls List with OJS journal count" = table2,
  "OJS journals matching Bealls List by country" = table3,
  "Active-Alive-DOAJ Breakdown for 684 OJS journals matching Bealls List" = table4,
  "Average Activity - Predatory vs Overall" = table5
)

write_xlsx(sheets, here::here("data/predatory/results/beall_ojs_matching_results.xlsx"))
```


